{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "byWTl5CFCiG1"
   },
   "source": [
    "#BehaviorScoringRun.ipynb\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMJLJFqT0Wnw"
   },
   "source": [
    "##ü™∞ This notebook is the entry point for the **BehaviorScoring** pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "It keeps\n",
    "implementation details inside modules and streamlines the workflow: set up the\n",
    "environment, select paths, run the analysis, and produce consistent scored outputs.The emphasis is a user-friendly, reproducible flow: clear separation of config from logic, minimal editing in one place, and version-pinned runs.\n",
    "\n",
    "This notebook guides you through a standard sequence: configure once, stage inputs, run scoring, and sync outputs. Edit only the cells marked **EDIT ME**; everything else should run as-is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ChMzidpseFl"
   },
   "source": [
    "#### Run order\n",
    "```\n",
    "1) Setup scoring environment  \n",
    "2) Import configs & stage to local mirrors  \n",
    "3) Run pipeline  \n",
    "4) Wrap-up cleaning\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPERI3-osqrL"
   },
   "source": [
    "#### Dependencies\n",
    "```\n",
    "BehaviorScoringMain.py\n",
    "BehaviorScoringFunctions.py\n",
    "BehaviorScoringConfig.py\n",
    "BehaviorScoringColabConfig.py\n",
    "ExperimentConfig.py\n",
    "PathConfig.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVCOcTFuDzSt"
   },
   "source": [
    "## 1. Setup scoring environment\n",
    "\n",
    "Prepare a clean, reproducible runtime and point the pipeline to your experiment.\n",
    "\n",
    "- Pin core library versions and show environment details.\n",
    "- Mount Google Drive and verify access.\n",
    "- Load **PathConfig** in Production or TEMP (dev) mode (EDIT ME)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18890,
     "status": "ok",
     "timestamp": 1754829895122,
     "user": {
      "displayName": "Matheus Farias",
      "userId": "17875474796050892951"
     },
     "user_tz": -60
    },
    "id": "rU6raWvFDqHU",
    "outputId": "46b9ef43-bf8e-45fc-ec81-047a30058150"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m418.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hPython: 3.11.13 | Platform: Linux-6.1.123+-x86_64-with-glibc2.35\n",
      "NumPy : 2.0.2 | pandas : 2.2.2 | sklearn : 1.6.1 | SciPy : 1.14.1\n"
     ]
    }
   ],
   "source": [
    "# Pin core library versions and show environment details\n",
    "\n",
    "# python==3.11.13\n",
    "# Pin libs to versions compatible with Colab's preinstalled stack.\n",
    "!pip install -q \\\n",
    "  numpy==2.0.2 \\\n",
    "  pandas==2.2.2 \\\n",
    "  scikit-learn==1.6.1 \\\n",
    "  scipy==1.14.1\n",
    "\n",
    "import sys, platform, numpy, pandas, sklearn, scipy\n",
    "print(\"Python:\", sys.version.split()[0], \"| Platform:\", platform.platform())\n",
    "print(\"NumPy :\", numpy.__version__,\n",
    "      \"| pandas :\", pandas.__version__,\n",
    "      \"| sklearn :\", sklearn.__version__,\n",
    "      \"| SciPy :\", scipy.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27862,
     "status": "ok",
     "timestamp": 1754829929692,
     "user": {
      "displayName": "Matheus Farias",
      "userId": "17875474796050892951"
     },
     "user_tz": -60
    },
    "id": "p9nAfKxh1LWq",
    "outputId": "a4b650a6-3e57-4600-d72b-c155900db261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Drive mounted ‚úì\n"
     ]
    }
   ],
   "source": [
    "#Mount Google Drive\n",
    "\n",
    "from pathlib import Path\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")\n",
    "drive_root = Path(\"/content/drive/My Drive\")\n",
    "assert drive_root.exists(), \"Drive root not found after mount.\"\n",
    "print(\"Drive mounted ‚úì\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7289,
     "status": "ok",
     "timestamp": 1754829940896,
     "user": {
      "displayName": "Matheus Farias",
      "userId": "17875474796050892951"
     },
     "user_tz": -60
    },
    "id": "1EzcALEyYyEn",
    "outputId": "8c3cbca8-82a2-4454-f526-fa62276e84be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEMP PathConfig injected ‚úì\n"
     ]
    }
   ],
   "source": [
    "# PathConfig: production or TEMP (dev)\n",
    "\n",
    "# ============================ EDIT ME (choose one) ==========================\n",
    "USE_TEMP_PATHCONFIG = True  # True = DEV (inject root); False = PROD (real file)\n",
    "\n",
    "# PROD: absolute path to your real PathConfig.py (with a real __EXP_ROOT__)\n",
    "pPathConfig = \"/content/drive/.shortcut-targets-by-id/1EvQfnCVnY3B5N4bSdunnJEZzZHMVxaoS/Matheus_e_Rodrigo/exp2/Protocols/Codes/Config/PathConfig.py\"\n",
    "\n",
    "# DEV: PathConfig.py to inject, and the temporary experimental root to use\n",
    "TEMP_PATHCONFIG      = \"/content/drive/My Drive/FHAnalysisPipeline/10DB/Protocols/Codes/Config/PathConfig.py\"\n",
    "TEMP_EXPERIMENT_ROOT = \"/content/drive/My Drive/FHAnalysisPipeline/10DB\"\n",
    "# ===========================================================================\n",
    "\n",
    "import sys, types, importlib.util\n",
    "\n",
    "if USE_TEMP_PATHCONFIG:\n",
    "    p_pathconfig = Path(TEMP_PATHCONFIG)\n",
    "    exp_root     = Path(TEMP_EXPERIMENT_ROOT)\n",
    "    assert p_pathconfig.exists(), \"TEMP PathConfig.py not found.\"\n",
    "    assert exp_root.exists(),     \"TEMP experimental root not found.\"\n",
    "\n",
    "    # Inject __EXP_ROOT__ in-memory (no disk edits)\n",
    "    code = p_pathconfig.read_text().replace('\"__EXP_ROOT__\"', f'\"{exp_root.as_posix()}\"')\n",
    "    PathConfig = types.ModuleType(\"PathConfig\")\n",
    "    exec(compile(code, str(p_pathconfig), \"exec\"), PathConfig.__dict__)\n",
    "    print(\"TEMP PathConfig injected ‚úì\")\n",
    "\n",
    "else:\n",
    "    p_pathconfig = Path(pPathConfig)\n",
    "    assert p_pathconfig.exists(), \"PathConfig.py not found.\"\n",
    "    spec = importlib.util.spec_from_file_location(\"PathConfig\", str(p_pathconfig))\n",
    "    PathConfig = importlib.util.module_from_spec(spec)\n",
    "    sys.modules[\"PathConfig\"] = PathConfig\n",
    "    spec.loader.exec_module(PathConfig)\n",
    "    print(\"Production PathConfig loaded ‚úì\")\n",
    "\n",
    "# Make Codes importable and preload the Config package\n",
    "sys.path.insert(0, str(Path(PathConfig.pCodes)))\n",
    "import importlib\n",
    "importlib.import_module(\"Config\")\n",
    "sys.modules[\"Config.PathConfig\"] = PathConfig  # satisfy 'from Config import PathConfig'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxJTT6hb8eyj"
   },
   "source": [
    "## 2. Import configs & stage to local mirrors\n",
    "\n",
    "Validate inputs on Drive, create fast local mirrors under `/content`, and stage\n",
    "only what needs work. Then build a local `PathConfig` that points the pipeline\n",
    "to the staged data and provides fresh convenience globs.\n",
    "\n",
    "- Import config modules and validate Drive inputs.\n",
    "- Create local mirrors and stage inputs/placeholders.\n",
    "- Build `LocalPathConfig` (Paths + globs) and verify counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38608,
     "status": "ok",
     "timestamp": 1754829983143,
     "user": {
      "displayName": "Matheus Farias",
      "userId": "17875474796050892951"
     },
     "user_tz": -60
    },
    "id": "nG1JeI7d8eLF",
    "outputId": "15ff8f47-c504-4d15-b07b-a4fa257f5ad1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================= LOADING FILES FROM DRIVE =================\n",
      "\n",
      "   Estimated: ~01:55 at 2.6 MB/s for 26/26 files\n",
      "\n",
      "   Inputs        : Tracked=13, Pose=13\n",
      "   Existing outs : Scored=0, ScoredError=0\n",
      "   Staging time  : 00:25\n",
      "\n",
      "======================= READY TO RUN =======================\n"
     ]
    }
   ],
   "source": [
    "from Config import ExperimentConfig\n",
    "from Config import BehaviorScoringConfig\n",
    "from Config import BehaviorScoringColabConfig\n",
    "import shutil, time\n",
    "\n",
    "# Optional: start fresh by clearing the local workspace\n",
    "CLEAN_LOCAL_ON_START = True\n",
    "\n",
    "# 1) Load canonical Drive paths\n",
    "drive_root, drive_paths = BehaviorScoringColabConfig.load_configs(PathConfig)\n",
    "\n",
    "# 2) Optionally clean local workspace for this experiment\n",
    "local_base = Path(\"/content/exp_runs\") / drive_root.name\n",
    "if CLEAN_LOCAL_ON_START and local_base.exists():\n",
    "    shutil.rmtree(local_base, ignore_errors=True)\n",
    "\n",
    "# 3) Validate required inputs (auto-detect pose if not given)\n",
    "pose_scoring = BehaviorScoringColabConfig.validate_inputs(drive_paths)\n",
    "\n",
    "# 4) Create local mirrors at /content/exp_runs/<exp>\n",
    "local_paths = BehaviorScoringColabConfig.local_mirrors(drive_root, drive_paths)\n",
    "\n",
    "# 5) Stage inputs + placeholders for existing outputs\n",
    "staged = BehaviorScoringColabConfig.stage_to_local(drive_paths, local_paths, pose_scoring)\n",
    "\n",
    "# 6) Build PathConfig rebased to /content with fresh convenience globs\n",
    "LocalPathConfig = BehaviorScoringColabConfig.make_local_pathconfig(PathConfig, local_paths)\n",
    "\n",
    "# 7) Verify globs (generators) point to local mirrors\n",
    "def _len_glob(g):\n",
    "    try: return sum(1 for _ in g)\n",
    "    except Exception: return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-e1gB2tlZ6_Y"
   },
   "source": [
    "## 3. Run pipeline\n",
    "\n",
    "Import the scoring modules, start a silent background sync (so outputs are\n",
    "pushed to Drive in small batches), and run the main behavior-scoring loop.\n",
    "\n",
    "- Import scoring modules used by the pipeline.\n",
    "- Start background sync (triggers after a small batch).\n",
    "- Run scoring, then always do a final sync."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47055,
     "status": "ok",
     "timestamp": 1754831204406,
     "user": {
      "displayName": "Matheus Farias",
      "userId": "17875474796050892951"
     },
     "user_tz": -60
    },
    "id": "_gsxNj1TaOVl",
    "outputId": "3d80b18f-a7c8-4984-fd20-b1b97d948679"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING: /content/exp_runs/10DB\n",
      "POSE:    TRUE\n",
      "\n",
      "FILES FOUND   -----------------------------------------------------   13\n",
      "TO SCORE      -----------------------------------------------------   13\n",
      "SKIPPING      ------------------------------------------------------   0\n",
      "              ----------------------------   scored: 0   ---   errors: 0\n",
      "\n",
      "SCORING: file 1/13 (0.00 s/file ‚Äì 00h00 eta)\n",
      "SCORING: file 2/13 (28.92 s/file ‚Äì 00h05 eta)\n",
      "SCORING: file 3/13 (28.86 s/file ‚Äì 00h05 eta)\n",
      "SCORING: file 4/13 (28.86 s/file ‚Äì 00h04 eta)\n",
      "SCORING: file 5/13 (28.81 s/file ‚Äì 00h04 eta)\n",
      "SCORING: file 6/13 (28.81 s/file ‚Äì 00h03 eta)\n",
      "SCORING: file 7/13 (28.86 s/file ‚Äì 00h03 eta)\n",
      "SCORING: file 8/13 (28.82 s/file ‚Äì 00h02 eta)\n",
      "SCORING: file 9/13 (28.90 s/file ‚Äì 00h02 eta)\n",
      "SCORING: file 10/13 (28.90 s/file ‚Äì 00h01 eta)\n",
      "SCORING: file 11/13 (28.90 s/file ‚Äì 00h01 eta)\n",
      "SCORING: file 12/13 (28.95 s/file ‚Äì 00h00 eta)\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ  ERROR: Insufficient exploration during baseline period. (Walk 14% | > 20% allowed)\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ  CR-EmptyTNT-20Control_3BlackOut-Female-6days-FH3-CamA-2024-07-19T14_41_45_fly0\n",
      "SCORING: file 13/13 (28.87 s/file ‚Äì 00h00 eta)\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ  ERROR: Insufficient exploration during baseline period. (Walk 9% | > 20% allowed)\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ  CR-EmptyTNT-20Control_3BlackOut-Female-6days-FH3-CamA-2024-07-19T15_05_58_fly3\n",
      "\n",
      "\n",
      "TIME SCORING   -----------------------------------------------------   00h00\n",
      "\n",
      "FILES FOUND    -----------------------------------------------------   13\n",
      "FILES SCORED   -----------------------------------------------------   11\n",
      "---------------------------------|  SESSION  |---|  GLOBAL  |\n",
      "ERRORS   ------------------------|  2 (15%)  |---|  2 (8%)  |\n",
      "---   low exploration   ---------|      2  |---|      2  |\n",
      "\n",
      "\n",
      "                        __(¬∑)<    ,\n",
      "                     O  \\_) )   c|_|\n",
      "               ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "================ SCORING AND SAVING COMPLETE ================\n",
      "\n",
      "              Synced outputs back to Drive.\n",
      "                 Sync time     : 00:03\n"
     ]
    }
   ],
   "source": [
    "from BehaviorScoring import BehaviorScoringFunctions as BSF\n",
    "from BehaviorScoring.BehaviorScoringMain import behavior_scoring_main\n",
    "\n",
    "# ============================ EDIT ME (run controls) =========================\n",
    "BATCH_SYNC_SIZE = 50   # trigger sync after this many new final files\n",
    "# ============================================================================\n",
    "\n",
    "# Start background sync (silent); pushes after an exact batch of new files\n",
    "BehaviorScoringColabConfig.start_background_sync(\n",
    "    local_paths, drive_paths, batch_size=int(BATCH_SYNC_SIZE))\n",
    "\n",
    "# Run the pipeline\n",
    "try:\n",
    "    behavior_scoring_main(LocalPathConfig, ExperimentConfig, BehaviorScoringConfig, BSF)\n",
    "finally:\n",
    "    # Always stop sync and push any remaining files\n",
    "    BehaviorScoringColabConfig.stop_background_sync()\n",
    "    BehaviorScoringColabConfig.sync_outputs_back(local_paths, drive_paths, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqsE6nwS2Skv"
   },
   "source": [
    "## 4. Wrap-up cleaning\n",
    "\n",
    "After you run the separate ‚ÄúRun pipeline‚Äù cells (in your workflow notebook),\n",
    "use this section to review output locations and optionally remove local mirrors.\n",
    "\n",
    "- Optionally remove local mirrors after final sync.\n",
    "- Confirm the cleanup result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qU0YUTwd23Bv"
   },
   "outputs": [],
   "source": [
    "# Optional: remove local mirrors now\n",
    "CLEAN_LOCAL_AT_END = True  # set True to clean up after sync\n",
    "if CLEAN_LOCAL_AT_END:\n",
    "    shutil.rmtree(local_paths.root, ignore_errors=True)\n",
    "    print(\"Local mirrors removed:\", local_paths.root)\n",
    "else:\n",
    "    print(\"Local mirrors preserved:\", local_paths.root)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "jVCOcTFuDzSt"
   ],
   "provenance": [
    {
     "file_id": "16tKjWwE73kITgiL5dkRTxk1G0J8RO-Bc",
     "timestamp": 1754680936603
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
